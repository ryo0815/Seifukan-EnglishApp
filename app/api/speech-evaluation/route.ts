import { NextRequest, NextResponse } from 'next/server'

const AZURE_SPEECH_KEY = process.env.AZURE_SPEECH_KEY
const AZURE_SPEECH_REGION = process.env.AZURE_SPEECH_REGION

async function getAzurePronunciationAssessment(audioBuffer: Buffer, referenceText: string) {
  if (!AZURE_SPEECH_KEY || !AZURE_SPEECH_REGION) {
    throw new Error('Azure Speech credentials are not configured in environment variables.')
  }

  // æ­£ã—ã„ç™ºéŸ³è©•ä¾¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
  const url = `https://${AZURE_SPEECH_REGION}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=en-US`
  
  // ç™ºéŸ³è©•ä¾¡ã®è¨­å®š
  const pronunciationConfig = {
    ReferenceText: referenceText,
    GradingSystem: 'HundredMark',
    Granularity: 'Phoneme',
    Dimension: 'Comprehensive',
  }

  const headers = {
    'Ocp-Apim-Subscription-Key': AZURE_SPEECH_KEY,
    'Content-Type': 'audio/wav',
    'Accept': 'application/json',
    'Pronunciation-Assessment': Buffer.from(JSON.stringify(pronunciationConfig)).toString('base64'),
  }

  console.log('Sending request to Azure Speech Service...')
  console.log('URL:', url)
  console.log('Headers:', { ...headers, 'Ocp-Apim-Subscription-Key': '***' })
  console.log('Audio buffer size:', audioBuffer.length)

  const response = await fetch(url, { 
    method: 'POST', 
    headers, 
    body: audioBuffer 
  })

  if (!response.ok) {
    const errorText = await response.text()
    console.error("Azure Error Response:", {
      status: response.status,
      statusText: response.statusText,
      headers: Object.fromEntries(response.headers.entries()),
      body: errorText
    })
    throw new Error(`Azure pronunciation assessment failed. Status: ${response.status}, Message: ${errorText}`)
  }

  const result = await response.json()
  console.log('Azure Response:', JSON.stringify(result, null, 2))
  return result
}

function getGradeFromScore(score: number): 'A' | 'B' | 'C' | 'D' | 'E' {
  if (score >= 90) return 'A'
  if (score >= 80) return 'B'
  if (score >= 70) return 'C'
  if (score >= 60) return 'D'
  return 'E'
}

const getAdviceForScore = (score: number): string[] => {
  const advice: string[] = [];

  if (score >= 95) {
    advice.push("ç´ æ™´ã‚‰ã—ã„ï¼å®Œç’§ãªç™ºéŸ³ã§ã™ã€‚");
    advice.push("è‡ªä¿¡ã‚’æŒã£ã¦æ¬¡ã«é€²ã¿ã¾ã—ã‚‡ã†ã€‚");
    advice.push("ãƒã‚¤ãƒ†ã‚£ãƒ–ã«è¿‘ã„ã€è‡ªç„¶ãªç™ºéŸ³ã§ã™ã€‚");
  } else if (score >= 85) {
    advice.push("é«˜å¾—ç‚¹ï¼ã¨ã¦ã‚‚è‰¯ã„ç™ºéŸ³ã§ã™ã€‚");
    advice.push("ç´°ã‹ã„éŸ³ã‚’æ„è­˜ã—ã¦ã€æ›´ã«æ”¹å–„ã—ã¾ã—ã‚‡ã†ã€‚");
    advice.push("ãƒªã‚ºãƒ ã¨æŠ‘æšã‚‚çœŸä¼¼ã¦ã¿ã¾ã—ã‚‡ã†ã€‚");
  } else if (score >= 75) {
    advice.push("è‰¯ã„èª¿å­ï¼è‡ªä¿¡ã‚’æŒã£ã¦ç™ºéŸ³ã—ã¾ã—ã‚‡ã†ã€‚");
    advice.push("å˜èªã®ç¹‹ãŒã‚Šã‚’ã€ã‚ˆã‚Šæ»‘ã‚‰ã‹ã«ã€‚");
    advice.push("èªå°¾ã®éŸ³ã¾ã§ã¯ã£ãã‚Šã¨ã€‚");
  } else if (score >= 60) {
    advice.push("æƒœã—ã„ï¼ã‚‚ã†å°‘ã—ã§ã™ã€‚");
    advice.push("å£ã®å½¢ã¨èˆŒã®å‹•ãã‚’æ„è­˜ã—ã¦å†æŒ‘æˆ¦ã€‚");
    advice.push("ãŠæ‰‹æœ¬ã‚’ã‚ˆãèã„ã¦ã€ãƒªã‚ºãƒ ã‚’çœŸä¼¼ã¾ã—ã‚‡ã†ã€‚");
  } else {
    advice.push("ã¾ãšã¯ãŠæ‰‹æœ¬ã‚’ã‚†ã£ãã‚Šèãã¾ã—ã‚‡ã†ã€‚");
    advice.push("ä¸€èªä¸€èªã‚’ã¯ã£ãã‚Šã¨ç™ºéŸ³ã—ã¾ã—ã‚‡ã†ã€‚");
    advice.push("ç„¦ã‚‰ãšã€è‡ªåˆ†ã®ãƒšãƒ¼ã‚¹ã§ç·´ç¿’ã—ã¾ã—ã‚‡ã†ã€‚");
  }
  return advice;
};

export async function POST(request: NextRequest) {
  try {
    console.log('\n--- ğŸš€ Starting Speech Evaluation (Vercel Compatible) ---')

    const formData = await request.formData()
    const audioFile = formData.get('audio') as File
    const referenceText = formData.get('referenceText') as string

    if (!audioFile || !referenceText) {
      return NextResponse.json({ error: 'Missing audio file or reference text.' }, { status: 400 })
    }

    console.log('Received audio file:', {
      name: audioFile.name,
      size: audioFile.size,
      type: audioFile.type
    })
    console.log('Reference text:', referenceText)

    const userAudioBuffer = Buffer.from(await audioFile.arrayBuffer())
    console.log('Converted to buffer, size:', userAudioBuffer.length)

    console.log('1. ğŸ”¬ Running Azure pronunciation assessment...')
    const azureResult = await getAzurePronunciationAssessment(userAudioBuffer, referenceText)
    
    const nBest = azureResult?.NBest?.[0]
    const pronunciationScore = nBest?.PronunciationAssessment?.PronScore || 0
    
    console.log('Azure result structure:', {
      hasNBest: !!azureResult?.NBest,
      nBestLength: azureResult?.NBest?.length,
      firstNBest: nBest,
      pronunciationScore
    })
    
    if (nBest) {
        console.log(`   â˜ï¸ Azure Result: SUCCESS | Score: ${pronunciationScore}`)
    } else {
        console.log(`   â˜ï¸ Azure Result: FAILED or No Score`)
    }

    console.log('2. ğŸ§® Calculating final score...')
    const grade = getGradeFromScore(pronunciationScore)
    const isPass = grade === 'A' || grade === 'B'
    const advice = getAdviceForScore(pronunciationScore)

    console.log(`   - Final Score: ${pronunciationScore}`)
    console.log(`   - Grade: ${grade} (${isPass ? 'Pass' : 'Fail'})`);
    console.log('--- âœ… Evaluation Complete --- \n')

    return NextResponse.json({
      success: true,
      pronunciationScore: pronunciationScore,
      accuracyScore: nBest?.PronunciationAssessment?.AccuracyScore || 0,
      fluencyScore: nBest?.PronunciationAssessment?.FluencyScore || 0,
      completenessScore: nBest?.PronunciationAssessment?.CompletenessScore || 0,
      grade: grade,
      isPass: isPass,
      advice: advice,
      recognizedText: nBest?.Display || "N/A",
      azureData: azureResult,
    })

  } catch (error) {
    console.error('\n--- âŒ Speech Evaluation CRASHED ---')
    const errorMessage = (error instanceof Error) ? error.message : 'An unknown error occurred'
    console.error(errorMessage)
    console.error(error)
    console.error('--- END OF CRASH REPORT ---\n')
    return NextResponse.json({ error: errorMessage }, { status: 500 })
  }
}